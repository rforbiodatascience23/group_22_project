---
title: "06_analysis_2"
author: "group22"
format:
  html:
    embed-resources: true
editor: visual
---

```{r}
df <- read_tsv("../data/02_dat_clean.tsv")

head(df)
```

```{r}
library(stats)

# Extract the features (exclude the outcome variable if applicable)
features <- df[, -c(df$Diabetes_binary)]

# Standardize the features
scaled_features <- scale(features)

# Perform PCA
pca_result <- princomp(scaled_features)

# Summary of PCA
summary(pca_result)

# Scree plot to visualize the variance explained by each principal component
plot(pca_result)

# Choose the number of components based on the scree plot and your requirements

# Extract the loadings (weights) for each variable in each principal component
loadings <- pca_result$loadings

# Select the desired number of principal components based on the scree plot
num_components <- 10  # Adjust this based on your analysis

# Keep the selected components
selected_components <- pca_result$scores[, 1:num_components]

# Merge with the outcome variable if applicable
# If your dataset includes an outcome variable, you might want to include it in the final dataset
# Example: merged_data <- cbind(selected_components, outcome = diabetes_data$outcome)

# Now, 'selected_components' contains the reduced set of features based on PCA

# Train your prediction model using the reduced features
# Example: model <- your_model_function(merged_data)

# Continue with the rest of your analysis
```

```{r}
# Scree plot
plot(pca_result)
```

```{r}
# Biplot
biplot(pca_result)
```

```{r}
# Cumulative variance plot
plot(cumsum(pca_result$sdev^2) / sum(pca_result$sdev^2), 
     xlab = "Number of Principal Components",
     ylab = "Cumulative Proportion of Variance Explained",
     type = "b")
```

```{r}
# Individual principal component contributions
barplot(abs(loadings[, 1]), main = "Absolute Loadings for PC1", names.arg = colnames(features))
```

```{r}
# Extract the proportion of variance explained by each component
variance_explained <- pca_result$sdev^2 / sum(pca_result$sdev^2)

# Create a data frame with component index, variance explained, cumulative sum, and variable names
variance_df <- data.frame(
  Component = 1:length(variance_explained),
  VarianceExplained = variance_explained,
  CumulativeVariance = cumsum(variance_explained)
)

# Add variable names to the data frame
variance_df$Variable <- colnames(features)

# Order the data frame by variance explained in descending order
variance_df <- variance_df[order(-variance_df$VarianceExplained), ]

# Print the ordered list with cumulative sum and variable names
print(variance_df)
```

```{r}
# Assuming you have performed PCA and selected the desired number of components
# Let's assume you have selected 5 components, update accordingly
num_components <- 11

# Use the selected components for training the model
selected_components <- pca_result$scores[, 1:num_components]

# Assuming your outcome variable is 'Diabetes_binary' and it's binary (0 or 1)
# Replace 'Diabetes_binary' with the actual name of your outcome variable
outcome_variable <- df$Diabetes_binary

# Split the data into training and testing sets
set.seed(123)  # for reproducibility
train_indices <- sample(seq_len(nrow(df)), 0.7 * nrow(df))  # 70% for training

# Create training and testing sets
train_data <- selected_components[train_indices, ]
train_outcome <- outcome_variable[train_indices]
test_data <- selected_components[-train_indices, ]
test_outcome <- outcome_variable[-train_indices]

# Train a logistic regression model
model <- glm(train_outcome ~ ., family = "binomial", data = as.data.frame(cbind(train_outcome, train_data)))

# Make predictions on the test set
predictions <- predict(model, newdata = as.data.frame(test_data), type = "response")

# Convert probabilities to binary predictions (0 or 1)
binary_predictions <- ifelse(predictions > 0.5, 1, 0)

# Evaluate the model
conf_matrix <- table(binary_predictions, test_outcome)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

# Print the confusion matrix and accuracy
print(conf_matrix)
cat("Accuracy:", accuracy, "\n")
```

```{r}
# Load necessary libraries
library(stats)

# Assuming your dataset is stored in a variable named 'df'
# Replace 'df' with the actual data frame name

# Set seed for reproducibility
set.seed(123)

# Split the data into training and testing sets without using caTools
split <- sample(1:nrow(df), 0.7 * nrow(df))
train_data <- df[split, ]
test_data <- df[-split, ]

# Train a logistic regression model
model <- glm(Diabetes_binary ~ ., family = "binomial", data = train_data)

# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to binary predictions (0 or 1)
binary_predictions <- ifelse(predictions > 0.5, 1, 0)

# Evaluate the model without using Metrics library
conf_matrix <- table(binary_predictions, test_data$Diabetes_binary)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

# Calculate precision, recall, and F1 score
precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])
f1 <- 2 * (precision * recall) / (precision + recall)

# Print evaluation metrics
cat("Confusion Matrix:\n", conf_matrix, "\n\n")
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1, "\n")
```
